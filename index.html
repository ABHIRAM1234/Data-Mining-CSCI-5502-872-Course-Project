<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="css/style.css">
    <title>Fire in Focus</title>
</head>
<body>
    <div class="container">
        <div class="tabs">
            <div class="tab" onclick="showTab('introduction')">Introduction</div>
            <div class="tab" onclick="showTab('data-exploration')">Data Exploration</div>
            <div class="tab" onclick="showTab('models-implemented')">Models Implemented</div>
            <div class="tab" onclick="showTab('conclusion-results')">Conclusion</div>
            <div class="tab" onclick="showTab('team')">Team</div>
        </div>
        
        <div id="introduction" class="tab-content">
            <h1>Fire in Focus: A Deep Learning Approach to Analyzing Wildfires</h1>
            <h2>The Nature of the topic</h2>
            <p>Wildfires are natural disasters that occur in regions experiencing extreme heat and dry conditions, significantly impacting both human society and the 
                environment. This project focuses on collecting and analyzing wildfire data from the United States to predict future occurrences. Our insights have led 
                us to understand that wildfires pose a serious threat, making it crucial for people to be prepared for potential dangers. This understanding serves as 
                the backbone of our project. We aim to develop a predictive analysis to ensure that we are prepared to face any potential risks. Our goal is to leverage wildfire 
                data to develop a predictive model that forecasts when and where wildfires are likely to occur and spread in the United States. This will ensure that hospitalization
                facilities are available when needed. In the long term, it could save lives by reducing the impact of future wildfire events.</p>
            <div class="image-container">
                <img src="images/wildfire_image1.png" alt="Wildfire in California">
                <p class="caption">The figure above is from the worst wildfire in the United States, which broke out in California in 2020.</p>
            </div>
            <h2>Why Wildfire Analysis is Important?</h2>
            <p>The main goal of this project is to benefit the people of the USA from wildfire threats. Wildfires are a serious concern due to their potential to cause 
                innocent deaths, highlighting the urgent need to develop a model for predicting future events. Ultimately, our project could reduce the number of lives 
                lost during wildfire incidents.
                Wildfires are increasingly common due to climate change. The diverse terrain and highly urbanized land in the USA make it particularly vulnerable. Wildfires are spreading across grasslands and vegetated areas, putting a significant amount of agricultural land at risk. This can lead to desertification, soil erosion, changes in water runoff, altered precipitation patterns, and reduced soil quality in affected regions.
                When nations destroy their flora, they miss out on economic opportunities. Furthermore, wildfires alter landscapes and destroy natural attractions. This project has the potential to serve as a model for all countries facing similar challenges.
                Finally, this project is also focused on safeguarding the environment. We aim to prevent wildfires from destroying vast areas of land. Wildfires not only devastate vegetation but also harm wildlife, thereby threatening biodiversity. The fire-prone areas in the USA serve as habitats for various species, and losing these habitats could significantly impact our ecosystem.
            </p>
            <div class="image-container">
                <img src="images/wildfire_image2.jpg" alt="Wildfire in California">
                <p class="caption">The above picture depicts the agriculture land lost during a wildfire in California 
                    2020.
                </p>
            </div>
            <div class="image-container">
                <img src="images/wildfire_image3.png" alt="Wildfire in California">
                <p class="caption">The table above illustrates the frequency of wildfire events and the acres burned each year in the United States.
                </p>
            </div>
            <div class="image-container">
                <img src="images/wildfire_image4.png" alt="Wildfire in California">
                <p class="caption">The graph above depicts the federal annual wildfire suppression costs for 1983-2021.
                </p>
            </div>
            <h2>Who is Affected?</h2>
            <p>Wildfires are catastrophic events that impact people and communities, leaving a long lasting impact on landscape and society. Residents in fire-prone 
                areas are affected the most and often live near wildlands, where the risk of wildfire is significantly high. When a wildfire occurs, these people face 
                immediate danger to their lives, and property. Beyond the physical threat they endure the psychological toll of loss of property, evacuation and 
                uncertainty. The destruction of homes and loss of personal belongings lead to a great sense of loss and trauma. Many families require physical 
                rebuilding and emotional healing as they deal with the trauma of the experience. In such emergencies, firefighters and emergency personnel play a 
                critical role but face high risks from wildfires. These individuals put their lives at risk to protect people and nature from the destructive fire. 
                The physical and mental strain of battling wildfires can be immense, leading to burnout, exhaustion, and in some cases, post-traumatic stress disorder 
                (PTSD). Firefighters often work long hours in hazardous conditions, facing extreme heat and unpredictable fire behavior. Their efforts are crucial and 
                often lack sufficient resources and support, which can hinder their ability to respond effectively to fires. The psychological impact of witnessing 
                destruction and loss can also affect their well-being so it is important to create support systems for those at the frontline.
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image5.png" alt="Wildfire in California">
                    <p class="caption">Civilians and first responders utilize a temporary refuge area established in a parking lot to stay safe during a Fire.
                    </p>
                </div>
                <p>
                    During and after a wildfire, local and state governments bear responsibility for resource allocation and ensuring public safety. These authorities must take critical
                     decisions about evacuations, resource deployment, and maintain clear communication with the public. Firefighting efforts pose a financial burden and can strain
                      budgets, leading to tough choices about where to allocate funds in the wake of a disaster. Recovery efforts require long-term planning and investment in rebuilding
                       infrastructure, which can take years to achieve. Government agencies need to collaborate with various stakeholders, including organizations and environmental 
                       groups, to effectively manage recovery and restoration 
                    efforts
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image6.png" alt="Wildfire in California">
                    <p class="caption">A firefighter battling the Creek Fire in the Cascadel Woods neighborhood of Madera County, California
                    </p>
                </div>
                <p>
                    Wildfires do not just affect people and nature but also entire ecosystems and wildlife. Many species are displaced or killed in fire events, leading
                     to declines in biodiversity and disruptions in food chains. Studies about the Australia bushfire in January 2020 show that nearly 3 billion animals 
                     were killed or displaced.  Forests and grasslands that are crucial for carbon capture and the air quality may take years or decades to recover. The 
                     loss of vegetation can also lead to soil erosion and increased runoff, which can affect water quality in nearby streams and rivers. The long-term
                      ecological consequences of wildfires require a holistic approach to land management, considering human needs and also the health of the ecosystems 
                      that sustain us.

                </p>
                <div class="image-container">
                    <img src="images/wildfire_image7.png" alt="Wildfire in California">
                    <p class="caption">Housing subdivision Coffey Park, Santa Rosa leveled by flames
                    </p>
                </div>
                <p>
                    Industries such as real estate, agriculture, and tourism are significantly affected by wildfires. Farmers may lose crops and livestock, leading to
                     financial hardships and food supply disruptions. The tourism industry can suffer as natural attractions become inaccessible or damaged. This 
                     impacts local economies that rely on visitors. In areas where property values depend on how close they are to natural landscapes, wildfires can 
                     lead to a decline in real estate markets, as potential buyers become scared to invest in areas with fire risks. Wildfires create a ripple effect 
                     that extends far and wide, underscoring the necessity for effective risk mitigation and management strategies that address the diverse needs of all
                      affected stakeholders.
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image8.png" alt="Wildfire in California">
                    <p class="caption">Proportion of Total Economic Impact Borne By Different Societal Segments from a  San Diego County Study
                    </p>
                </div>
                <h2>What has been done so far and what are the gaps?</h2>
                <p>
                    Wildfires have become increasingly prevalent and are causing environmental issues, further exacerbated by climate change and human activities. These 
                    events pose immediate threats to life and property while also having long-term ecological impacts. Historically, wildfires have been a natural part of 
                    many ecosystems by contributing to nutrient cycling and habitat formation. However, the frequency and intensity of wildfires have risen exponentially in
                     recent years, bringing a need for improved prediction and management strategies. Recent advancements in technology and data analysis have provided new
                      tools to address these challenges, yet significant gaps remain in our understanding and response capabilities. In recent years, there has been 
                      substantial progress in wildfire prediction techniques. The integration of satellite imagery, remote sensing, and machine learning algorithms has
                       transformed the data collection and analysis. For example, NASA and other agencies have developed satellite systems that monitor vegetation moisture
                        levels, temperature, and wind patterns, which are key indicators of a risk of wildfire. These tools have helped researchers and fire management 
                        agencies to identify high-risk areas and assess the potential for fire ignition and spread more accurately than in the past. Predictive modeling, 
                        such as the use of Weather Research and Forecasting (WRF) models, has enhanced the ability to forecast fire behavior under varying weather 
                        conditions.
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image9.png" alt="Wildfire in California">
                    <p class="caption">Nighttime view of two wildfires in Southern California, based on observations taken by NASA’s ECOsystem Spaceborne Thermal Radiometer Experiment on 
                        Space Station (ECOSTRESS). The areas in red show where the fire was active when the observations were taken and the area in orange show above-average nighttime 
                        ground temperatures, which are likely caused by a heat wave
                    </p>
                </div>
                <p>
                    Data mining and analytics play a vital role in wildfire management by analyzing historical fire data alongside meteorological conditions. Researchers have 
                    developed models that can predict fire outbreaks with a decent degree of accuracy. Techniques such as clustering and classification have been utilized to 
                    identify patterns and correlations within large datasets, leading to more effective resource allocation and risk management strategies. Data-driven models
                     have been instrumental in guiding controlled burns and firebreak constructions, which are essential for preventing wildfires from spreading uncontrollably.
                      Additionally, community-based monitoring systems have helped local populations to report fire hazards, further enhancing early warning capabilities. 
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image10.png" alt="Wildfire in California">
                    <p class="caption">Firing the woods in a South Carolina forest with a custom made driptorch mounted on an ATV. The device spits flaming fuel oil from the side which instantly ignites the leaf litter.
                    </p>
                </div>
                <p>
                    Despite these advancements, significant challenges remain in wildfire prediction and management. One of the primary challenges is the lack of real-time 
                    data integration from multiple sources, such as social media, local reports, and environmental sensors. Current models mostly rely on historical data 
                    which may not accurately reflect the changing climatic conditions or land use patterns. Many existing prediction models do not account for the 
                    complexities of human behavior during fire events, such as evacuation patterns and decision-making processes. This can hinder effective communication 
                    and coordination among emergency responders and the affected communities. Machine learning has promising solutions to address some of these challenges 
                    in wildfire prediction and management. Advanced algorithms can analyze vast amounts of unstructured data from various sources, enabling real-time risk 
                    assessments and adaptive management strategies. Deep learning models can process satellite images and remote sensing data to detect changes in land cover
                     and vegetation health, providing critical insights for fire risk assessment. However, the application of machine learning in this field needs to be
                      advanced, and there is a need for collaboration between data scientists, ecologists, and fire management professionals to develop models that can be
                       deployed in real-world scenarios.
                    
                </p>
                <div class="image-container">
                    <img src="images/wildfire_image11.png" alt="Wildfire in California">
                    <p class="caption">Average Temperature across Forest Service Land in US in the last 40 years
                    </p>
                </div>
                <p>
                    Fire spread modeling has also seen significant advancements, yet traditional fire spread models like FARSITE have limitations in terms of computational 
                    efficiency. Recently there has been a focus on developing new models that can better capture the physical processes involved in fire spread while 
                    remaining computationally efficient. For example, the U.S. Forest Service has been collaborating with Google Research on a new fire behavior model 
                    that incorporates detailed fuel characteristics and can be run in real time using machine learning techniques to reduce computation times. Additionally, 
                    cellular automata models have shown promise in simulating fire behavior, when combined with machine learning techniques to improve efficiency and 
                    accuracy. As climate change continues to impact fire dynamics, ongoing research and collaboration will be essential for developing effective strategies
                     to mitigate the risks posed by wildfires. By focusing on these areas, we can lay the foundation for more resilient ecosystems and safer communities in 
                     the face of increasing wildfire threats.
                    
                </p>
            <h2>Research Questions</h2>
            <ol>
                <li>How confident are the satellite information that give us wildfire data</li>
                <li>What are the different instruments and satellites used for wildfire imagery</li>
                <li>What are the different hotspots? Is it vegetation? Volcano? Other static land source? Offshore detection?</li>
                <li>Wildfire pattern across USA from 2000-2024</li>
                <li>Were wildfire rates consistent across each year?</li>
                <li>Which State in USA has had the most number of wildfires since 2000?</li>
                <li>Wildfire pattern across the state with most wildfires from 2000-2024</li>
                <li>Is the above trend similar to that of USA as a whole?</li>
                <li>Which months of the year on an average have had the most wildfires for that state</li>
                <li>Is there a correlation with the temperature during those months and the wildfire frequency?</li>
            </ol>
        </div>

        <div id="data-exploration" class="tab-content">

            <h1>Data Exploration</h1>
            <h2>Objective</h2>
            <p>The objective of this project is to develop a wildfire prediction and analysis system for California by leveraging 
                wildfire data from satellite observations and weather data. By integrating wildfire hotspots with meteorological
                 conditions such as temperature, humidity, wind speed, and precipitation, the project aims to forecast wildfire
                  occurrences and provide actionable insights. This analysis will improve understanding of wildfire patterns and 
                  support more effective wildfire management strategies.</p>
            
            <h2>Data Collection</h2>
            <ul>
                <li>NASA Firms API for wildfires - <a href="https://firms.modaps.eosdis.nasa.gov/api/">https://firms.modaps.eosdis.nasa.gov/api/</a></li>
                <li>Weather API - <a href="https://open-meteo.com/">https://open-meteo.com/</a></li>
            </ul>
            <h3>Weather Data Attributes</h3>
            <p>Most weather variables are given as an instantaneous value for the indicated hour. Some variables,
                 like precipitation, are calculated from the preceding hour as an average or sum.</p>
            <style>
                table {
                    width: 50%; 
                    margin: 20px auto; 
                    border-collapse: collapse; 
                }
                th, td {
                    border: 1px solid #333; 
                    padding: 10px; 
                    text-align: center; 
                }
                th {
                    background-color: #f2f2f2; 
                }
        </style>     
        <table>
            <thead>
                <tr>
                    <th>Variable</th>
                    <th>Valid Time</th>
                    <th>Unit</th>
                    <th>Description</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>temperature_2m</td>
                    <td>Instant</td>
                    <td>°C (°F)</td>
                    <td>Air temperature at 2 meters above ground</td>
                    
                </tr>
                <tr>
                    <td>Air temperature at 2 meters above ground</td>
                    <td>Instant</td>
                    <td>%</td>
                    <td>Relative humidity at 2 meters above ground</td>
                   
                </tr>
                <tr>
                    <td>dew_point_2m</td>
                    <td>Instant </td>
                    <td>°C (°F)	</td>
                    <td>Dew point temperature at 2 meters above ground</td>
                   
                </tr>
                <tr>
                    <td>apparent_temperature</td>
                    <td>Instant</td>
                    <td>°C (°F)</td>
                    <td>Perceived temperature combining wind chill factor, relative humidity and solar radiation</td>
                   
                </tr>
                <tr>
                    <td>precipitation</td>
                    <td>Preceding hour sum</td>
                    <td>mm (inch)</td>
                    <td>Total precipitation (rain, showers, snow) sum of the preceding hour</td>
                   
                </tr>
                <tr>
                    <td>Rain</td>
                    <td>Preceding hour sum</td>
                    <td>mm (inch)</td>
                    <td>Only liquid precipitation of the preceding hour including local showers and rain from large scale systems.</td>
                   
                </tr>
                <tr>
                    <td>Snowfall</td>
                    <td>Preceding hour sum</td>
                    <td>cm (inch)</td>
                    <td>Snowfall amount of the preceding hour in centimeters. For the water equivalent in millimeter, divide by 7. E.g. 7 cm snow = 10 mm precipitation water equivalent</td>
                   
                </tr>
                <tr>
                    <td>snow_depth</td>
                    <td>Instant</td>
                    <td>meters</td>
                    <td>Snow depth on the ground. Snow depth in ERA5-Land tends to be overestimated.</td>
                   
                </tr>
                <tr>
                    <td>weather_code</td>
                    <td>Instant</td>
                    <td>WMO code</td>
                    <td>Weather condition as a numeric code.</td>
                   
                </tr>
                <tr>
                    <td>pressure_msl surface_pressure</td>
                    <td>Instant</td>
                    <td>hPa</td>
                    <td>Atmospheric air pressure reduced to mean sea level (msl) or pressure at surface.</td>
                   
                </tr>
                <tr>
                    <td>cloud_cover</td>
                    <td>Instant</td>
                    <td>%</td>
                    <td>Total cloud cover as an area fraction</td>
                   
                </tr>
                <tr>
                    <td>cloud_cover_low</td>
                    <td>Instant</td>
                    <td>%</td>
                    <td>Low level clouds and fog up to 2 km altitude</td>
                   
                </tr>
                <tr>
                    <td>cloud_cover_mid</td>
                    <td>Instant</td>
                    <td>%</td>
                    <td>Mid level clouds from 2 to 6 km altitude</td>
                   
                </tr>
                <tr>
                    <td>cloud_cover_high</td>
                    <td>Instant</td>
                    <td>%</td>
                    <td>High level clouds from 6 km altitude</td>
                   
                </tr>
                <td>shortwave_radiation</td>
                <td>Preceding hour mean </td>
                <td>W/m²</td>
                <td>Shortwave solar radiation as average of the preceding hour.</td>
                </tr>
                </tr>
                <td>direct_radiation &
                    direct_normal_irradiance</td>
                <td>Preceding hour mean</td>
                <td>W/m²</td>
                <td>Direct solar radiation as average of the preceding hour on the horizontal plane and the normal plane</td>
                </tr>
                </tr>
                <td>diffuse_radiation</td>
                <td>Preceding hour mean</td>
                <td>W/m²</td>
                <td>Diffuse solar radiation as average of the preceding hour</td>
                </tr>
                <tr>
                    <td>cloud_cover_mid</td>
                    <td>Preceding hour mean</td>
                    <td>W/m²</td>
                    <td>Mid level clouds from 2 to 6 km altitude</td>
                   
                </tr>
                <tr>
                    <td>global_tilted_irradiance</td>
                    <td>Preceding hour sum</td>
                    <td>W/m²</td>
                    <td>Total radiation received on a tilted pane as average of the preceding hour. </td>
                   
                </tr>
                <tr>
                    <td>sunshine_duration</td>
                    <td>Preceding hour sum</td>
                    <td>Seconds</td>
                    <td>Number of seconds of sunshine of the preceding hour per hour calculated by direct 
                        normalized irradiance exceeding 120 W/m², following the WMO definition.</td>
                   
                </tr>


                <tr>
                    <td>et0_fao_evapotranspiration</td>
                    <td>Preceding hour sum</td>
                    <td>mm(inch)</td>
                    <td>ET₀ Reference Evapotranspiration of a well watered grass field. 
                    Based on FAO-56 Penman-Monteith equations ET₀ is calculated from temperature, wind speed, humidity and solar radiation.</td>
                </tr>
                <tr>
                    <td>vapour_pressure_deficit</td>
                    <td>Instant</td>
                    <td>kPa</td>
                    <td>Vapor Pressure Deificit (VPD) in kilopascal (kPa).</td>
                   
                </tr>
                <tr>
                    <td>wind_speed_10m & wind_speed_100m</td>
                    <td>Instant</td>
                    <td>km/h (mph, m/s, knots)</td>
                    <td>Wind speed at 10 meters above ground.</td>
                   
                </tr>
                <tr>
                    <td>wind_direction_10m</td>
                    <td>Instant</td>
                    <td>°</td>
                    <td>Wind speed at 10 or 100 meters above ground. Wind speed on 10 meters is the standard level.</td>
                   
                </tr>
                <tr>        
                    <td>wind_direction_100m</td>
                    <td>Instant</td>
                    <td>°</td>
                    <td>Wind direction at 100 meters above ground</td>
                   
                </tr>
                <tr>
                    <td>wind_gusts_10m</td>
                    <td>Instant</td>
                    <td>km/h (mph, m/s, knots)</td>
                    <td>Gusts at 10 meters above ground as a maximum of the preceding hour</td>
                   
                </tr>
                <tr>
                    <td>soil_temperature_0_to_7cm,
                        soil_temperature_7_to_28cm,
                        soil_temperature_28_to_100cm,
                        soil_temperature_100_to_255cm</td>
                    <td>Instant</td>
                    <td>°C (°F) </td>
                    <td>Average temperature of different soil levels below ground.</td>
                   
                </tr>
                <tr>
                    <td>soil_moisture_0_to_7cm,
                        soil_moisture_7_to_28cm,
                        soil_moisture_28_to_100cm,
                        soil_moisture_100_to_255cm</td>
                    <td>Instant</td>
                    <td>m³/m³</td>
                    <td>Average soil water content as volumetric mixing ratio at 0-7, 7-28, 28-100 and 100-255 cm depths.</td>
                   
                </tr>
                
            </tbody>
        </table>
        <h3>VIIRS NRT Attribute Fields</h3>
        <table>
            <thead>
                <tr>
                    <th>Attributes</th>
                    <th>Description</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Latitude</td>
                    <td>Center of nominal 375 m fire pixel</td>
                </tr>
                <tr>
                    <td>Longitude</td>
                    <td>Center of nominal 375 m fire pixel</td>
                </tr>
                <tr>
                    <td>Bright_ti4</td>
                    <td>VIIRS I-4 channel brightness temperature of the fire pixel measured in Kelvin.</td>
                </tr>
                <tr>
                    <td>Scan</td>
                    <td>The algorithm produces approximately 375 m pixels at nadir. Scan and track reflect actual pixel size.</td>
                </tr>
                <tr>
                    <td>Track</td>
                    <td>The algorithm produces approximately 375 m pixels at nadir. Scan and track reflect actual pixel size.</td>
                </tr>
                <tr>
                    <td>Acq_Date</td>
                    <td>Date of VIIRS acquisition.</td>
                </tr>
                <tr>
                    <td>Acq_Time</td>
                    <td>Time of acquisition/overpass of the satellite (in UTC).</td>
                </tr>
                <tr>
                    <td>Satellite</td>
                    <td>N= Suomi National Polar-orbiting Partnership (Suomi NPP)</td>
                </tr>
                <tr>
                    <td>Confidence</td>
                    <td>This value helps gauge the quality of individual hotspot/fire pixels. Confidence values are set to low, nominal, and high. Low confidence pixels are typically associated with sun glint or lower relative temperature anomaly.</td>
                </tr>
                <tr>
                    <td>Version</td>
                    <td>Version identifies the collection and source of data processing: Near Real-Time (NRT suffix added) or Standard Processing.</td>
                </tr>
                <tr>
                    <td>Bright_ti5</td>
                    <td>I-5 Channel brightness temperature of the fire pixel measured in Kelvin.</td>
                </tr>
                <tr>
                    <td>FRP</td>
                    <td>FRP depicts the pixel-integrated fire radiative power in megawatts (MW). The VIIRS 375 m fire detection algorithm optimizes response over small fires while balancing false alarms.</td>
                </tr>
                <tr>
                    <td>Type*</td>
                    <td>0 = presumed vegetation fire, 1 = active volcano, 2 = other static land source, 3 = offshore detection.</td>
                </tr>
                <tr>
                    <td>DayNight</td>
                    <td>D = Daytime fire, N = Nighttime fire.</td>
                </tr>
            </tbody>
        </table>
        

            <h2>Step 1 - Collecting Wildfire Data</h2>
            <p>We used the NASA FIRMS API, which provides data on fires and hotspots detected from satellite observations.</p>
            <div class="image-container">
                <img src="images\raw_1.jpg" alt="raw_data 1">
                <img src="images\raw_2.jpg" alt="raw_data 2">
                <img src="images\raw_3.jpg" alt="raw_data 3">
                <p class="caption">The above screenshots show the raw data collected from multiple satellites            
                </p>
            </div>
            <div class="image-container">
                <img src="images\raw_merged.jpg" alt="Merged wildfire raw dataset">
                <p class="caption">The merged wildfire raw dataset consists of all wildfires that occurred in the USA from 2000-2024.</p>
            </div>
            
            <p>The column CONFIDENCE has mixed data types. The confidence levels are low(l), nominal(n), and high(h). Only about 15% of the data within the confidence attribute is numeric,
                so we binned the values into different ranges. Instances with confidence = l were dropped from the training set,
                 as they were likely misclassified due to sun glare or cloud reflection. Daytime fire pixels with low confidence are linked to sun glint and lower relative temperature anomalies (<15K)
                   in mid-infrared channel I4. Nominal confidence pixels are those without sun glint and with a temperature anomaly of >15K
                    in day or nighttime data. Fire pixels with high confidence are associated with day or nighttime saturation.</p>
            <div class="image-container">
                <img src="images\confidence_hist.jpg" alt="Confidence Histogram">
                <p class="caption">Histogram showing the distribution of confidence levels of satellite wildfire detection.</p>
            </div>
            <div class="image-container">
                <img src="images\timeandday.jpg" alt="day and night">
                <p class="caption">Histogram showing the distribution of wildfires based on day and night</p>
            </div>
            <h2>Geospatial Analysis</h2>
            <p>The following carousel of density plots depicts the wildfire distribution throught the years of 2000,2005,2010,2015,2020,2024,
                 respectively in the United States.</p>

            <style>
                    .carousel {
                        width: 100%;
                        max-width: 600px;
                        margin: 0 auto;
                        position: relative;
                        overflow: hidden;
                    }
                    .carousel img {
                        width: 100%;
                        height: auto;
                        display: none; /* Hide all images initially */
                    }
                    .carousel img.active {
                        display: block; /* Show active image */
                    }
                    .carousel-controls {
                        position: absolute;
                        top: 50%;
                        width: 100%;
                        display: flex;
                        justify-content: space-between;
                        transform: translateY(-50%);
                    }
                    .carousel-controls button {
                        background-color: rgba(0, 0, 0, 0.5);
                        color: white;
                        border: none;
                        padding: 10px;
                        cursor: pointer;
                    }
                </style>

            <div class="carousel">
                <img src="images/US1.jpg.png" alt="Image 1" class="active">
                <img src="images/US2.jpg.png" alt="Image 2">
                <img src="images/US3.jpg.png" alt="Image 3">
                <img src="images/US4.jpg.png" alt="Image 4">
                <img src="images/US5.jpg.png" alt="Image 5">
                <img src="images/US6.jpg.png" alt="Image 6">
                <div class="carousel-controls">
                    <button id="prev">❮</button>
                    <button id="next">❯</button>
                </div>
            </div>

            <script>
                const images = document.querySelectorAll('.carousel img');
                let currentIndex = 0;

                document.getElementById('next').addEventListener('click', function() {
                    images[currentIndex].classList.remove('active');
                    currentIndex = (currentIndex + 1) % images.length;
                    images[currentIndex].classList.add('active');
                });

                document.getElementById('prev').addEventListener('click', function() {
                    images[currentIndex].classList.remove('active');
                    currentIndex = (currentIndex - 1 + images.length) % images.length;
                    images[currentIndex].classList.add('active');
                });
            </script>

            <div class="image-container">
                <img src="images\high_2013.jpg" alt="Wildfire Temporal Plot">
                <p class="caption">The above attached Temporal plot implies that more than 75% of all occurrences of wildfires in the United States 
                    since 2000 have happened after 2013!
                </p>
            </div>
            <div class="image-container">
                <img src="images\cal_high.jpg" alt="California histogram Plot">
                <p class="caption">The above histogram shows the wildfire count of the United States from 2000 to present.</p>
            </div>
            <div class="image-container">
                <img src="images\dense_plot_cal.jpg" alt="Wildfire Density Plot">
                <p class="caption">Density Plot of wildfires in California in the year 2024, with a high concentration in Southern
                     California.</p>
            </div>
            <p>California has got the most wildfires which accounts to almost one-eigth of 
                the total wildfires of the United States.
            </p>
            <div class="image-container">
                <img src="images\month.jpg" alt="Month Frequency Plot">
                <p class="caption">Frequency Plot of wildfires in California.</p>
                <p>Frequency Plot to identify what time of the year contributes to the most wildfires in California.
                It turns out that July to September has the most number of wildfires. These also happen to be the hottest 
                months of the year in California</p>
            </div>

            <style>
             
                .message {
                    font-family: 'Arial', sans-serif; 
                    font-size: 2.5em; 
                    font-weight: bold; 
                    text-align: center; 
                    color: #ff4500; 
                    background-color: #f0f8ff; 
                    padding: 20px; 
                    border: 2px solid #ffa07a; 
                    border-radius: 10px; 
                    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2); 
                    margin: 50px auto; 
                    width: 80%; 
                    animation: pulse 2s infinite; 
                }

                @keyframes pulse {
                    0% { transform: scale(1); }
                    50% { transform: scale(1.05); }
                    100% { transform: scale(1); }
                }

                .message span {
                    text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3); 
                }
            </style>
            
            <div class="message">
                <span>Alright! Now we are heading to Step 2!</span>
            </div>
            <h2>Step 2 - Collecting Weather Data</h2>
            <p>We used the Open-Meteo weather API to gather weather data. Open-Meteo is an open-source weather API which 
                gives hourly weather data. We used the Python API client. The API has a daily limit of 10000 so we restricted
                our satellite data to only Southern California from 2020 and fetched the weather data for respective 
                latitude and longitudes.</p>
            <p>The weather dataset contains the following attributes:</p>     
            <div class="image-container">
                    <img src="images\training.jpg" alt="Attribute Details">
            </div>

            <h2>Feature Analysis and EDA</h2>

            <h4>Snow Depth</h4>
            <p>Snow depth is the only Column with null values. 
                99% of all snow_depth occurrences are 0 indicating that snow does not happen when there is  wildfire. Therefore all the nulls will be replaced by the Mode=0.
            </p>
            <div class="image-container">
                <img src="images\snow_1.jpg" alt="Null values">
                <img src="images\snow_2.jpg" alt="Details on Snow Depth Attribute">
            </div>

            <h4>Temperature</h4>
            <div class="image-container">
                <img src="images\temp.jpg" alt="Temperature Plot">
                <p class="caption">Months 6-9 (June to September) have a higher average temperature compared to the rest of the year
                     which is very similar to the wildfire-month trend seen earlier above. Temperature is therefore a critical 
                     variable when it comes to wildfires.</p>
            </div>   
            <div class="image-container">
                <img src="images\heatmap.jpg" alt="Temperature heatmap Plot">
                <p class="caption">Correlation heatmap of weather and fire variables.</p>
            </div>
            <div class="image-container">
                <img src="images\pairplot.jpg" alt="PairPlot of key features">
                <p class="caption">There is an apparent negative correlation between temperature and humidity,
                     but the other features like wind speed and precipitation do not have a lot of correlation between them.</p>
            </div>    
            <div class="image-container">
                <img src="images\boxplot.jpg" alt="boxPlot of relative humidity">
                <p class="caption">There is a very marginal difference in relative humidity in the presence or absence of a wildfire.</p>
            </div> 
            <style>

                .qa-container {
                    font-family: 'Verdana', sans-serif; 
                    width: 80%; 
                    margin: 40px auto; 
                    padding: 20px;
                    background-color: #f9f9f9; 
                    border-radius: 8px; 
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); 
                }
        
                .question {
                    font-size: 1.8em; 
                    font-weight: bold; 
                    color: #ff6347; 
                    margin-bottom: 10px; 
                }
        
                .answer {
                    font-size: 1.2em; 
                    color: #333; 
                    padding-left: 15px; 
                    border-left: 3px solid #ffa07a; 
                }
                .qa-container:hover {
                    background-color: #fff0f5;
                    box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
                }
            </style>
            <div class="qa-container">
                <div class="question">Q:How was the target variable "Fire" or "No Fire" created?</div>
                <div class="answer">A: By integrating wildfire data with weather data based on latitude, longitude and date, we identified occurrences of
                     wildfires with a target label of 1. The rows that remained unmerged correspond to instances
                      where wildfires did not occur. To achieve a balanced
                       dataset, we quantified the positive class labels from 2020 to 2024 and subsequently conducted a random 
                       sampling of an equivalent number of data points from the unmatched dataset. This produced an equal
                        quantity of positive and negative class labels, with 56,948 instances for each. The data set comprises
                         a total of 113,896 rows.</div>
            </div>

            <h2>Training Dataset</h2>
            <p>The training dataset for our wildfire prediction model combines weather data from a weather API and satellite data from NASA's API. The dataset has features such as temperature, humidity, wind speed, and cloud cover. The target variable is "fire", where a value of 1 indicates the occurrence of a wildfire, and 0 indicates no wildfire.</p>
                 <p>The following image gives us a detailed description of all the attributes used:</p>
                 <div class="collage">
                    <img src="images/attr_1.jpg" alt="Image 1">
                    <img src="images/attr_2.jpg" alt="Image 2">
                    <img src="images/attr_3.jpg" alt="Image 3">
                    <img src="images/attr_4.jpg" alt="Image 4">
                </div>
        </div>

        <div id="models-implemented" class="tab-content">
            <h1>Models Implemented</h1>
            <p>With our training data prepared, the next step is to leverage this data to build a predictive model. The objective of this predictive analysis is to determine whether a wildfire is likely to occur in the near future based on weather forecasts for a given region in California. This task falls under supervised machine learning and is specifically a binary classification problem.</p>
            <p>To prepare the data for modeling, we separated the features from the target variable and performed an 80:20 train-test split. We then standardized the numerical features using <code>StandardScaler</code>, transforming them to follow a standard normal distribution (mean = 0, variance = 1). This transformation ensures that the models can interpret the data more effectively, improving their predictive performance.</p>
        
            <div class="image-container">
                <figure>
                    <img src="./screenshots/dataset_before_transformation.png" alt="Dataset Before Transformation">
                    <figcaption>Dataset Before Transformation</figcaption>
                </figure>
                <figure>
                    <img src="./screenshots/dataset_after_transformation.png" alt="Dataset After Transformation">
                    <figcaption>Dataset After Transformation</figcaption>
                </figure>
            </div>
                    
            <p>For the purpose of this project, we developed 8 machine learning models:</p>
            <ol>
                <li>Logistic Regression</li>
                <li>Decision Tree</li>
                <li>Support Vector Machine</li>
                <li>Random Forest</li>
                <li>LightGBM</li>
                <li>XGBoost</li>
                <li>K-Nearest Neighbors</li>
                <li>Naive Bayes Classifier</li>
            </ol>
            <p>Every model developed has undergone feature selection, feature engineering, K-Fold Cross Validation, hyperparameter tuning, model building, and evaluation metrics. We will now discuss in detail all the steps carried out for each of the 8 models.</p>
            
            <section id="Logistic Regression">
                <h2>Logistic Regression</h2>
                <p>The basic assumption of a Logistic Regression Classifier is that every feature or attribute used to model should be independent. In other words, there should not be any multicollinearity between the variables. Therefore, as part of building this model, we removed all variables that were highly correlated with each other (as seen in the image below).</p>
                <div class="image-container">
                    <img src="./Results/logistic regression/highly_correlated_features.png" alt="Highly Correlated Features">
                </div>
                <p>As part of the feature engineering process, we discretized every attribute by using the Standard Scaler. This process converts each feature attribute to a standard normal distribution with a mean of 0 and variance of 1.</p>
                
                <p>The next step was to validate the model. This is a crucial step before building any machine learning model as it helps prevent overfitting. By applying K-Fold Cross Validation on 5 different sets, we obtained a mean accuracy score of 0.583, which is poor as it is barely better than randomly guessing any class.</p>
                
                <p>To address this, we further tuned the hyperparameters of the logistic regression model using a Python library called HyperOpt. This library automates the process of finding the best combination of hyperparameters, which can improve the model's performance. HyperOpt randomly samples hyperparameters from a defined search space (shown in the image below) and uses a probabilistic model-based optimization technique that balances exploration and exploitation.</p>
                <div class="image-container">
                    <img src="./Results/logistic regression/hyperparamater_tuning.png" alt="Hyperparameter Tuning">
                </div>
                <p>After fitting the model onto an objective function to improve accuracy, we obtained the best hyperparameters of the model to be:</p>
                <ul>
                    <li>C = 0.01667000925475309</li>
                    <li>max_iter = 200</li>
                    <li>solver = 'liblinear'</li>
                    <li>penalty = 'l2'</li>
                </ul>
                <p>'C' here is the inverse of regularization (1/lambda). A small C value indicates stronger regularization, which adds a large penalty to strong coefficients to reduce overfitting or increase underfitting. Max_iter = 200 indicates the algorithm’s threshold for the number of iterations before the optimization algorithm converges. 'Liblinear' is a solver based on the coordinate descent algorithm. The 'penalty' indicates the type of regularization applied to the model. L1 is Lasso, L2 is Ridge, and Elastic Net is a mix of both.</p>
                
                <p>We then split the entire dataset into train and test sets (80% for training and 20% for testing) and built the Logistic Regression model using the best hyperparameters obtained. Despite this, we achieved only an accuracy score of 0.59, with the confusion matrix shown below. The AUC-ROC score, which helps describe the model's ability to distinguish between classes, was also only 0.62.</p>
                
                <p>These results indicate a major limitation of the Logistic Regression model: it relies on the data being linearly separable, which was not the case with this wildfire prediction data.</p>
    
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <div style="flex: 1; max-width: 45%; text-align: center;">
                        <img src="./Results/logistic regression/conf_matrix.png" alt="Confusion Matrix" style="width: 100%;">
                        <p class="caption">Confusion Matrix showing the performance of the Logistic Regression model.</p>
                    </div>
                    <div style="flex: 1; max-width: 45%; text-align: center;">
                        <img src="./Results/logistic regression/roc_auc.png" alt="ROC-AUC Curve and Score" style="width: 100%;">
                        <p class="caption">ROC-AUC curve and score indicating the model's ability to distinguish between classes.</p>
                    </div>
                </div>
            </section>
            
            <section id="decision tree">
                <h2>Decision Tree</h2>
                <p>A Decision Tree is a supervised machine learning algorithm used for classification and regression tasks. It makes decisions based on a tree-like structure where each node represents a decision made on an attribute and the edges represent the possible outcomes. There are three main components of the tree:</p>
                <ul>
                    <li><strong>Root Node:</strong> The topmost node that contains the entire dataset, and from which the first decision is made.</li>
                    <li><strong>Decision Nodes:</strong> These nodes split the data based on feature values (e.g., "Is age > 30?").</li>
                    <li><strong>Leaf Nodes:</strong> The final decision or prediction is made at the leaf node.</li>
                </ul>
                <p>At each decision node, the algorithm chooses the best feature based on a criterion like Gini impurity or information gain. This process is repeated recursively for each subset of data until a stopping condition is met. During predictions, the data flows through the tree based on the feature values, and the final output is made by the leaf node it ends up in.</p>
            
                <p>The baseline Decision Tree model performed decently, but we improved its performance by tuning its hyperparameters.</p>
                
                <div class="image-container">
                    <img src="./Results/decision tree/training_acc.png" alt="Baseline Training Acc">
                    <img src="./Results/decision tree/baseline_results.png" alt="Baseline Model Results">
                </div>
                            
                <h3>Hyperparameter Tuning with Optuna</h3>
                <p>We used <strong>Optuna</strong> to perform hyperparameter tuning to find the best Decision Tree model. Optuna is a hyperparameter optimization framework designed for automatic and efficient tuning of machine learning models. It uses algorithms to intelligently explore the hyperparameter space, identifying the optimal combination of parameters that maximizes a specific metric. Optuna supports techniques like Bayesian optimization and Tree-structured Parzen Estimators (TPE). This reduces computational costs compared to grid or random search, especially for complex models like Decision Trees.</p>
            
                <p>For this tuning, we defined an objective function in which Optuna evaluates different combinations of hyperparameters for a Decision Tree model. The function computes the model’s performance on a cross-validation (CV) set and returns the mean accuracy score.</p>
            
                <h3>Hyperparameters Tuned</h3>
                <ul>
                    <li><strong>max_depth:</strong> Controls the maximum depth of the decision tree. A larger value will allow the tree to grow deeper to capture more complex patterns. However, deeper trees may lead to overfitting. Limiting the depth helps prevent overfitting.</li>
                    <li><strong>min_samples_split:</strong> Specifies the minimum number of samples required to split an internal node. Higher values prevent the model from learning overly specific patterns and reduce overfitting by making splits more conservative.</li>
                    <li><strong>min_samples_leaf:</strong> Defines the minimum number of samples required to be at a leaf node. Higher values ensure that leaves contain more data points, which helps the model avoid overfitting by reducing the chance of learning from outliers or noise.</li>
                    <li><strong>max_features:</strong> Specifies the number of features to consider when looking for the best split. It helps control the complexity of the tree. Lower values can prevent overfitting by making the tree less sensitive to the data, while higher values allow more features for each split, increasing complexity.</li>
                    <li><strong>ccp_alpha:</strong> This parameter is used for cost-complexity pruning. It controls the pruning of the tree after it is fully grown. Larger values of ccp_alpha lead to more aggressive pruning, which can help simplify the tree and reduce overfitting. A smaller value allows the tree to grow deeper and potentially overfit the training data.</li>
                    <li><strong>criterion:</strong> The criterion parameter specifies the function used to measure the quality of a split. 'gini' is the Gini impurity, while 'entropy' uses the information gain from the data. Both criteria aim to reduce impurity in the nodes. This choice can influence the model's performance but both perform equally well in most cases.</li>
                </ul>
            
                <p>We conducted an Optuna study with 200 trials to find the optimal hyperparameter combinations that maximize cross-validation accuracy.</p>
                <div class="image-container">
                    <img src="./Results/decision tree/hyperparameter_tuning.png" alt="Hyperparameter Tuning">
                    <img src="./Results/decision tree/best_hyperparameters_clean.png" alt="Best Hyperparameters">
                    <img src="./Results/decision tree/tuned_model_cv_scores.png" alt="Tuned Model Cross-Validation Scores">
                </div>
                <h3>Model Performance After Hyperparameter Tuning</h3>
                <p>Below are the results of the new model. It is evident that the training accuracy has decreased compared to the baseline model, indicating that the new model is less overfitted.</p>
                
                <div class="image-container">
                    <img src="./Results/decision tree/tuned_training_acc.png" alt="Tuned Training Accuracy">
                    <img src="./Results/decision tree/tuned_results.png" alt="Tuned Results">
                </div>

                <p>After hyperparameter tuning, the new model showed the following improvements compared to the baseline model:</p>
                <ul>
                    <li><strong>Accuracy:</strong> Increased, reflecting better overall performance.</li>
                    <li><strong>Precision:</strong> Improved, showing the model is more accurate in predicting positives.</li>
                    <li><strong>F1 Score:</strong> Improved, indicating a better balance between precision and recall.</li>
                </ul>
            
                <p>However, recall decreased slightly, suggesting a trade-off in performance. Specifically:</p>
                <ul>
                    <li><strong>True Positives:</strong> Increased, indicating the model is better at identifying actual positive instances.</li>
                    <li><strong>False Negatives:</strong> Decreased, showing the model is less likely to miss positive instances.</li>
                    <li><strong>True Negatives:</strong> Decreased, indicating that the model is more aggressive in predicting positives, which may increase false positives.</li>
                </ul>
            
                <p>The overall performance indicates that while the tuned model is better at detecting positives, it has become slightly more prone to false positives. This reflects a shift in the model’s balance toward identifying positive instances more frequently.</p>
            
                <h3>Feature Importances and ROC-AUC Evaluation</h3>
                <p>To further understand the tuned model's performance, we analyzed the feature importances and evaluated the model's effectiveness using the ROC-AUC curve.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/decision tree/feature_importance1.png" alt="Feature Importance" style="flex: 1; max-width: 45%;">
                    <img src="./Results/decision tree/roc_auc.png" alt="ROC-AUC Curve and Score" style="flex: 1; max-width: 45%;">
                </div>
            </section>

            <section id="svm">
                <h2>Support Vector Machine (SVM)</h2>
                <p>SVM is a supervised learning algorithm used for classification tasks. It finds the optimal hyperplane that best separates the data points of different classes in a high-dimensional feature space. The objective of SVM is to maximize the margin, which is the distance between the hyperplane and the nearest data points (support vectors) from each class. This margin maximization ensures better generalization to unseen data.</p>
                
                <p>SVM can effectively handle linear and non-linear classification by using kernel functions, which map the data into higher-dimensional spaces where a linear hyperplane can separate the classes. The ability to transform data using kernels makes SVM powerful for solving complex classification problems.</p>
            
                <h3>Baseline Model Performance</h3>
                <p>The baseline SVM model was evaluated using standard metrics. However, the results show that the model struggled, with a significant number of false positives, where it incorrectly classified non-target instances as target instances. This highlights the challenges of the baseline SVM model in capturing the underlying patterns effectively.</p>
                <p><strong>Computational Complexity:</strong> SVMs are computationally expensive for large datasets and complex kernel functions. Training involves solving a quadratic optimization problem, which scales poorly with the number of data samples. This makes SVM less suitable for massive datasets unless simpler approximations like Linear SVM are used. The high computational cost is a trade-off for SVM’s ability to handle non-linear, separable data.</p>
                
                <div class="image-container">
                    <img src="./Results/svm/baseline_train_acc.png" alt="Baseline Training Accuracy">
                    <img src="./Results/svm/baseline_eval.png" alt="Baseline Model Results">
                </div>
    
                <h3>Hyperparameter Tuning with RandomizedSearchCV</h3>
                <p>We performed randomized search using RandomizedSearchCV, which is a hyperparameter tuning method that randomly samples from the hyperparameter space. Unlike GridSearchCV, which searches through all possible combinations of hyperparameters, RandomizedSearchCV randomly samples a fixed number of combinations from the hyperparameter space and evaluates them.</p>
            
                <p><strong>Key Parameters in RandomizedSearchCV:</strong></p>
                <ul>
                    <li><strong>param_dist:</strong> A dictionary of hyperparameters from which random values are sampled.</li>
                    <li><strong>n_iter:</strong> The number of hyperparameter combinations to evaluate.</li>
                    <li><strong>cv:</strong> Number of cross-validation folds (cv=3 for 3-fold cross-validation).</li>
                    <li><strong>n_jobs:</strong> Number of CPU cores used for parallel computation (n_jobs=-1 utilizes all available cores for efficiency).</li>
                </ul>
            
                <h3>Tuned Hyperparameters</h3>

                <div class="image-container">
                    <img src="./Results/svm/hyperparameter_tuning.png" alt="Hyperparameters">
                </div>

                <ul>
                    <li><strong>C (Penalty parameter):</strong> Controls the trade-off between a smooth decision boundary and correct classification of training examples.</li>
                    <li><strong>gamma (Kernel coefficient):</strong> Defines the influence of individual training examples on the decision boundary.</li>
                    <li><strong>kernel (Kernel function):</strong> Specifies the type of decision boundary to use for data separation (e.g., 'linear', 'rbf', 'poly').</li>
                    <li><strong>degree (Degree of the polynomial kernel):</strong> Determines the degree of the polynomial used for the decision boundary (only applicable for 'poly' kernel).</li>
                    <li><strong>tol (Tolerance for stopping criterion):</strong> Controls the tolerance for optimization and stopping criteria.</li>
                    <li><strong>shrinking (Shrinking heuristic):</strong> Boolean parameter that determines whether the shrinking heuristic is applied.</li>
                </ul>
            
                <h3>Results After Tuning</h3>

                <div class="image-container">
                    <img src="./Results/svm/best_hyperparameters.png" alt="Hyperparameter tuning results">
                    <p class="caption">These are the best hyperparameters obtained after tuning.</p>
                </div>

                <p>Below are the results of the tuned model on the training and testing data. We can see an improvement in the training accuracy</p>

                <div class="image-container">
                    <img src="./Results/svm/tuned_model_training_acc.png" alt="Tuned model training accuracy">
                    <img src="./Results/svm/tuned_model_results.png" alt="Tuned model testing accuracy">
                </div>

                <p>After hyperparameter optimization using RandomizedSearchCV, the SVM model demonstrated significant improvement across all evaluation metrics:</p>
                <ul>
                    <li><strong>Recall:</strong> Improved notably, indicating the model’s improved ability to correctly identify positive instances.</li>
                    <li><strong>False Positives:</strong> Reduced, though they remain a concern, suggesting that the model still struggles with balancing precision and recall.</li>
                </ul>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/svm/feature_importance.png" alt="Feature Importance" style="flex: 1; max-width: 45%;">
                    <img src="./Results/svm/roc_auc_curve.png" alt="ROC-AUC Curve and Score" style="flex: 1; max-width: 45%;">
                </div>
    
                <p>The tuned model’s performance validates the effectiveness of hyperparameter tuning in addressing SVM's sensitivity to data and parameter configurations. While the false positive rate remains an area for improvement, the overall enhancements in metrics demonstrate the value of careful optimization.</p>
            </section>       
            <section id="random-forest">
                <h2>Random Forest</h2>
                <p>Random Forest is an ensemble method that builds upon multiple decision trees during training and then combines their results for better predictions, making it robust. The biggest advantage of Random Forests over Decision Trees is that they generally have the same bias but lower variance than a single predictor. Another feature of Random Forest is its ability to create a feature importance table, which looks at how much the tree nodes that use that feature reduce impurity on average.</p>
                
                <p>When building a Random Forest Model for the purpose of wildfire prediction, we emphasized reducing the dimensionality of the dataset. This was done using Random Forest's feature importance. It was of no surprise to see that features like snow, rain, and precipitation contributed least to the prediction of wildfires and therefore were ranked very low. Features like evapotranspiration (a feature that incorporates temperature, wind speed, humidity, and solar radiation), soil temperature, etc., were ranked high.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/random forest/feature_importance1.png" alt="Feature Importance1">
                    <img src="./Results/random forest/feature_importance2.png" alt="Feature Importance2">
                </div>

                <h3>Model Evaluation and Cross-Validation</h3>
                <p>Similar to the models above, we performed a 5-fold cross-validation to prevent the chance of overfitting. The mean accuracy score obtained was 0.835, which indicates that this model promises to generalize really well on average. For this model, we explored <strong>Optuna</strong>, an open-source hyperparameter tuning Python library. It employs techniques like Bayesian Optimization, Tree Structured Parzen Estimators (TPE), and random search. Not only this, Optuna also allows users to define an objective function, which optimizes through iterative trials.</p>
            
                <h3>Hyperparameter Tuning with Optuna</h3>
                <p>The images below show the search space initialized for Optuna’s objective function and the best set of hyperparameters obtained after 50 trials.</p>
            
                <h4>Key Hyperparameters Tuned:</h4>

                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/random forest/tuned_hyperparameters.png" alt="Hyperparameters Tuned" style="flex: 1; max-width: 45%;">
                    <img src="./Results/random forest/best_hyperparameters.png" alt="Best Hyperparameter Values" style="flex: 1; max-width: 45%;">
                </div>

                <ul>
                    <li><strong>n_estimators:</strong> The number of decision trees in the forest. The fewer the trees, the less variance, but computational time can increase.</li>
                    <li><strong>max_depth:</strong> The maximum depth of each decision tree. Larger values can fit complex hidden patterns but may lead to overfitting.</li>
                    <li><strong>min_samples_split:</strong> The minimum number of samples needed to split an internal node. High values indicate that nodes have sufficient data before splitting, which can help prevent overfitting.</li>
                    <li><strong>min_samples_leaf:</strong> The minimum number of samples required to be present in a leaf node. This helps prevent overfitting by ensuring that leaves have sufficient data.</li>
                    <li><strong>max_features:</strong> 'sqrt' is an algorithm that considers the square root of the total number of features at each split.</li>
                    <li><strong>criterion:</strong> The function used to measure the quality of a split, either Gini impurity or entropy.</li>
                </ul>
            
                <h3>Results After Hyperparameter Optimization</h3>
                <p>After obtaining the best hyperparameters for the wildfire prediction model, we split the dataset into 80% train and 20% test. We then trained a Random Forest Classification Model. The classification metrics and AUC-ROC score obtained are shown below.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/random forest/conf_matrix.png" alt="Confusion Matrix" style="flex: 1; max-width: 45%;">
                    <img src="./Results/random forest/roc_auc_curve.png" alt="ROC-AUC Curve" style="flex: 1; max-width: 45%;">
                </div>

                <h3>Model Performance</h3>
                <p>This model performed really well at accurately predicting wildfires. Not only did it achieve a good accuracy score, but it also received an excellent ROC score, indicating that the model can effectively distinguish between wildfire occurrences and non-occurrences.</p>
            </section>
            <section id="light-gbm">
                <h2>Light GBM</h2>
                <p>Light GBM (Gradient Boosting Machine) is a newer variation of Gradient Boosting Algorithms developed by Microsoft. It was designed for high-performing machine learning problems, particularly in situations where training speed, memory efficiency, and scalability are critical. Like other models, we developed a K-Fold Cross Validation methodology to evaluate how well the model generalized on average and to check if the model had high variance on the test set. We obtained an accuracy score of 0.79 across the 5 folds, indicating that the model performed fairly well across multiple subsets of the dataset.</p>
                
                <h3>Hyperparameter Tuning with RandomizedSearchCV</h3>
                <p>We then performed hyperparameter tuning using <strong>RandomizedSearchCV</strong>. This algorithm randomly selects a combination of hyperparameters and evaluates their performance, offering a much more efficient way than performing GridSearchCV. This optimization algorithm helped us find the best set of hyperparameters.</p>
            
                <div class="image-container">
                    <img src="./Results/Light GBM/best_hyperparameters.png" alt="Confusion Matrix">
                </div>

                <h4>Key Hyperparameters Tuned:</h4>
                <ul>
                    <li><strong>colsample_bytree:</strong> This parameter gives us the fraction of features to sample to build each tree. In this case, 84% of features are randomly selected for each tree.</li>
                    <li><strong>learning_rate:</strong> This parameter controls how fast or slow the model converges to the optimal solution. A low value increases computation time, while a high learning rate can overshoot the optimal solution.</li>
                    <li><strong>max_depth:</strong> The maximum depth of each tree, which helps in controlling the complexity of the model.</li>
                    <li><strong>min_child_samples:</strong> The minimum number of samples required in a child node. A higher value prevents the model from creating overly specific trees and helps with regularization.</li>
                    <li><strong>n_estimators:</strong> The number of trees in the ensemble model.</li>
                    <li><strong>num_leaves:</strong> The number of leaves in each tree. This affects the complexity of the trees and the ability of the model to capture intricate patterns.</li>
                    <li><strong>reg_alpha:</strong> The L1 (Lasso) regularization term on leaf weights, which adds a penalty for large weights to reduce the risk of overfitting.</li>
                    <li><strong>reg_lambda:</strong> The L2 (Ridge) regularization term on leaf weights, which is similar to reg_alpha but squared.</li>
                    <li><strong>subsample:</strong> This parameter indicates that about 62% of the data samples were used to train each tree. This helps prevent overfitting and increases the robustness of the ensemble method.</li>
                </ul>
            
                <h3>Model Performance</h3>
                <p>Similar to the models described above, the Light GBM model was trained using the best hyperparameters obtained. The images below show that ensemble methods, in general, are better at capturing the essence of predicting wildfires compared to distance-based or linear models.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/Light GBM/conf_matrix.png" alt="Confusion Matrix" style="flex: 1; max-width: 45%;">
                    <img src="./Results/Light GBM/roc_auc_curve.png" alt="ROC-AUC Curve" style="flex: 1; max-width: 45%;">
                </div>
            
            </section>
            <section id="xgboost">
                <h2>Extreme Gradient Boosting (XGBoost)</h2>
                <p>XGBoost is a machine learning algorithm based on gradient boosting, designed for both regression and classification tasks. It builds decision trees sequentially, where each new tree tries to correct the errors made by the previous ones. The final prediction is a combination of all the trees, which helps provide high accuracy and robustness.</p>
                
                <h3>Key Features</h3>
                <ul>
                    <li><strong>Regularization:</strong> XGBoost supports both L1 and L2 regularization to control the complexity of the model and reduce overfitting.</li>
                    <li><strong>Pruning:</strong> XGBoost uses tree pruning to stop tree splitting when further splits do not improve performance. This improves computational efficiency and prevents unnecessary complexity.</li>
                </ul>
            
                <h3>Baseline Model</h3>
                <p>For our baseline model, we performed 5-fold cross-validation, achieving a mean accuracy of 82.3%. On the training data, the baseline model achieved an accuracy of 86.79%. However, false positives were high on the test data, where the model incorrectly predicted wildfire occurrences in non-fire scenarios.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/xgboost/baseline_cv_scores.png" alt="Baseline Model Cross-Validation Scores" style="width: 45%; object-fit: contain;">
                    <img src="./Results/xgboost/baseline_results.png" alt="Baseline Model Results" style="width: 45%; object-fit: contain;">
                </div>
                
                <h3>Hyperparameter Tuning with Bayesian Optimization</h3>
                <p>To optimize the XGBoost model, we used <strong>Bayesian Optimization</strong>, a hyperparameter tuning technique that efficiently explores the hyperparameter space by modeling the relationship between hyperparameters and the model's performance using a probabilistic surrogate function.</p>
                <p>Unlike grid or random search, Bayesian Optimization:</p>
                <ul>
                    <li>Learns from previous evaluations and identifies the most promising regions of the search space for further exploration.</li>
                    <li>Balances exploration and exploitation, iteratively selecting new hyperparameters to maximize performance while minimizing unnecessary evaluations.</li>
                </ul>
                <p>We utilized <strong>BayesSearchCV</strong> from the scikit-optimize library, which combines Bayesian Optimization with cross-validation for hyperparameter tuning. The process started with random samples, and subsequent iterations used prior results to intelligently select new hyperparameters.</p>
            
                <h3>Hyperparameters Tuned</h3>

                <div class="image-container">
                    <img src="./Results/xgboost/hyperparameters_tuned.png" alt="Hyperparameters Tuned">
                    <p class="caption">These are the hyperparameters that were tuned</p>
                </div>
                
                <ul>
                    <li><strong>learning_rate:</strong> Determines the size of the steps during each boosting round. Lower values lead to slower learning but often result in a more accurate model, while higher values risk overshooting the optimal solution.</li>
                    <li><strong>n_estimators:</strong> Specifies the number of boosting rounds (trees) in the model. More estimators allow the model to learn more but increase training time and risk overfitting.</li>
                    <li><strong>max_depth:</strong> The maximum depth of each decision tree. Deeper trees allow the model to learn more complex patterns but may lead to overfitting.</li>
                    <li><strong>subsample:</strong> Determines the fraction of training samples used to grow each tree. Lower values add randomness, reducing overfitting but possibly underfitting the data.</li>
                    <li><strong>colsample_bytree:</strong> Specifies the fraction of features used when constructing each tree. Lower values reduce feature dependency, preventing overfitting.</li>
                    <li><strong>gamma:</strong> Sets the minimum reduction in loss required to make a further split on a node. Higher values make the model more conservative, requiring larger reductions in loss before splitting.</li>
                </ul>
            
                <div class="image-container">
                    <img src="./Results/xgboost/best_hyperparameters.png" alt="Best Hyperparameter Values">
                    <img src="./Results/xgboost/tuned_model_cv_scores.png" alt="Tuned Model Cross-Validation Score">
                </div>

                <h3>Model Performance</h3>
                <p>After tuning, the model achieved a training accuracy of 97.81%. On the test dataset, the results showed significant improvement over the baseline model:</p>

                <div class="image-container">
                    <img src="./Results/xgboost/tuned_model_training_acc.png" alt="Tuned Model Training Accuracy">
                    <img src="./Results/xgboost/tuned_results.png" alt="Tuned Model Results">
                </div>

                <ul>
                    <li><strong>Accuracy:</strong> Improved, reflecting better overall performance.</li>
                    <li><strong>True Positives:</strong> Improved, indicating better detection of actual wildfire occurrences.</li>
                    <li><strong>False Positives:</strong> Reduced, demonstrating a better balance in predictions compared to the baseline.</li>
                </ul>
                
                <p>Despite the improvements, the model is still slightly biased toward predicting wildfire occurrences, leading to occasional false positives. This trade-off highlights the challenge of balancing the detection of true positives while minimizing false positives.</p>
                <p>We used the AUC-ROC score and the ROC curve to assess the model's performance. These metrics provide insights into the trade-offs between sensitivity (recall) and specificity across different classification thresholds, enabling a comprehensive evaluation of the model's predictive capability.</p>

                <div class="image-container">
                    <img src="./Results/xgboost/roc_curve.png" alt="AUC-ROC Curve">
                </div>

                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/xgboost/feature importance1.png" alt="Feature Importance 1" style="flex: 1; max-width: 45%;">
                    <img src="./Results/xgboost/feature_importance2.png" alt="Feature Importance 2" style="flex: 1; max-width: 45%;">
                </div>
            
            </section>
            <section id="knn">
                <h2>K-Nearest Neighbors (KNN)</h2>
                <p>K-Nearest Neighbors (KNN) is a simple machine learning algorithm that predicts the class of a data point based on its closest neighbors. The performance of KNN heavily depends on selecting the right number of neighbors (k) and the distance metric used to measure similarity.</p>
            
                <h3>Baseline Model Performance</h3>
                <p>The training accuracy of the baseline KNN model was 84.2%, while the test accuracy was 77.21%. The confusion matrix and classification metrics revealed areas for improvement, particularly in balancing recall and precision.</p>
            
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/knn/baseline_training_acc.png" alt="Baseline Training Accuracy" style="flex: 1; max-width: 45%;">
                    <img src="./Results/knn/baseline_test_metrics.png" alt="Baseline Testing Metrics" style="flex: 1; max-width: 45%;">
                </div>

                <div class="image-container">
                    <img src="./Results/knn/baseline_conf_matrix.png" alt="Baseline Confusion Matrix">
                </div>

                <h3>Hyperparameter Tuning with Bayesian Optimization</h3>
                <p>The KNN algorithm's key parameters include:</p>
                <ul>
                    <li><strong>n_neighbors:</strong> Determines how many neighbors to consider. Larger values create smoother decision boundaries, while smaller values capture finer patterns but may lead to overfitting.</li>
                    <li><strong>weights:</strong> Decides whether all neighbors contribute equally (uniform) or if closer neighbors have more influence (distance).</li>
                    <li><strong>metric:</strong> Specifies the distance metric (e.g., Euclidean, Manhattan, Minkowski) used to calculate distances between points.</li>
                </ul>
                <p>To optimize the KNN model, we used Bayesian Optimization with <strong>BayesSearchCV</strong>, fine-tuning parameters such as n_neighbors (1 to 20), weights (uniform or distance), and metric (Euclidean, Manhattan, or Minkowski). The optimization process ran for 50 iterations with 5-fold cross-validation to ensure robustness.</p>
            
                <h3>Optimized Model Performance</h3>
                <p>After hyperparameter tuning, the best configuration was:</p>
                <ul>
                    <li><strong>n_neighbors:</strong> 5</li>
                    <li><strong>weights:</strong> distance</li>
                    <li><strong>metric:</strong> Manhattan</li>
                </ul>
                
                <div class="image-container">
                    <img src="./Results/knn/tuned_model_metrics.png" alt="Tuned Model Metrics" style="flex: 1; max-width: 45%;">
                    <img src="./Results/knn/tuned_model_classification_report.png" alt="Tuned Model Classification Report" style="flex: 1; max-width: 45%;">
                </div>

                <p>This optimized configuration boosted the model's performance, achieving the following results:</p>
                <ul>
                    <li><strong>Test Accuracy:</strong> 79.40%</li>
                    <li><strong>Precision:</strong> 75.91%</li>
                    <li><strong>Recall:</strong> 86.82%</li>
                    <li><strong>F1-Score:</strong> 81.00%</li>
                </ul>
                <p>The optimized KNN model effectively balances simplicity, complexity, and accuracy, making it a reliable choice for wildfire prediction.</p>
            
                <h3>Confusion Matrix and Misclassifications</h3>

                <div class="image-container">
                    <img src="./Results/knn/tuned_model_conf_matrix.png" alt="Tuned Model Confusion Matrix">
                </div>

                <p>After tuning, the model correctly identified:</p>
                <ul>
                    <li><strong>True Negatives:</strong> 8,084</li>
                    <li><strong>True Positives:</strong> 10,003</li>
                </ul>
                <p>However, it misclassified:</p>
                <ul>
                    <li><strong>False Positives:</strong> 3,174</li>
                    <li><strong>False Negatives:</strong> 1,519</li>
                </ul>
            
                <h3>Cross-Validation and AUC Score</h3>

                <div class="image-container">
                    <img src="./Results/knn/tuned_model_cv_scores.png" alt="Tuned Model CV Scores">
                </div>

                <p>The classification report reflects the precision, recall, and F1-score for the fine-tuned KNN model. It achieved an overall accuracy of 79%, with precision and recall values of 76% and 87% for class 1 (wildfire). The cross-validation scores across 5 folds ranged between 78.26% and 78.35%, confirming the model's consistency and reliability across different subsets of data.</p>
                <p>With an <strong>AUC score of 0.87</strong>, the ROC curve reflects excellent discrimination, indicating that the fine-tuned KNN model effectively predicts wildfire occurrences with high confidence.</p>
                
                <div class="image-container">
                    <img src="./Results/knn/tuned_model_auc_roc.png" alt="Tuned Model ROC-AUC">
                </div>
            
            </section>
            <section id="naive-bayes">
                <h2>Naive Bayes</h2>
                <p>Naive Bayes is a classification algorithm that uses Bayes' Theorem to predict outcomes. It assumes that all features are independent given the class label, making it computationally efficient and well-suited for high-dimensional datasets.</p>
            
                <h3>Baseline Model Performance</h3>
                <p>Our Naive Bayes model leverages Bayes' theorem to predict the likelihood of wildfire occurrences. During the initial training phase, the model exhibited a training accuracy of 52.92%. The baseline confusion matrix highlighted some challenges, with:</p>
                <ul>
                    <li><strong>True Negatives:</strong> 1,897</li>
                    <li><strong>True Positives:</strong> 10,261</li>
                    <li><strong>False Positives:</strong> 9,361</li>
                    <li><strong>False Negatives:</strong> 1,260</li>
                </ul>

                <div class="image-container">
                    <img src="./Results/naive_bayes/baseline_training_acc.png" alt="Tuned Model ROC-AUC">
                </div>

                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/naive_bayes/baseline_conf_matrix.png" alt="Baseline Model Confusion Matrix" style="flex: 1; max-width: 45%;">
                    <img src="./Results/naive_bayes/baseline_classification_report.png" alt="Baseline Model Classification Report" style="flex: 1; max-width: 45%;">
                </div>

                <p>The classification report further revealed a significant imbalance in the model’s predictions, with the precision and F1-scores for non-wildfire cases being notably lower.</p>
            
                <h3>Hyperparameter Tuning with Bayesian Optimization</h3>
                <p>We focused on optimizing the <strong>var_smoothing</strong> parameter, which adds a small value to the variance of each feature to ensure stable probability calculations and avoid division by zero errors. Using Bayesian optimization, we explored different values for this parameter and selected the best-performing configuration.</p>
                <p>We evaluated the model through 5-fold cross-validation to prevent overfitting and measure its generalizability. The model achieved a mean cross-validation accuracy of 57.71%, showing consistent performance across data splits. However, its overall performance was limited due to the complexity of the dataset, as indicated by an <strong>AUC-ROC score of 0.61</strong>.</p>
            
                <h3>Model Performance After Tuning</h3>
                <p>While the model could distinguish between wildfire and non-wildfire cases, its predictions lacked precision. The <strong>var_smoothing</strong> parameter played a crucial role in stabilizing the model, as it helps prevent zero probabilities by adding a small value to the variance of each feature. However, higher smoothing values improve generalization, which may reduce the model's sensitivity to finer details in the data.</p>
                <p>Despite using Bayesian optimization for fine-tuning, the post-tuning results remained consistent with the baseline, indicating that Naive Bayes' inherent simplicity might limit its ability to model complex relationships in this dataset.</p>
                
                <div class="image-container">
                    <img src="./Results/naive_bayes/tuned_model_metrics.png" alt="Tuned Model ROC-AUC">
                </div>

                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/naive_bayes/baseline_conf_matrix.png" alt="Baseline Model Confusion Matrix" style="flex: 1; max-width: 45%;">
                    <img src="./Results/naive_bayes/tuned_model_classification_report.png" alt="Tuned Model Classification Report" style="flex: 1; max-width: 45%;">
                </div>

                <h3>Final Results</h3>
                <p>After tuning, the model's accuracy was 53.38%, with the same metrics for precision, recall, and F1-score as the baseline. The cross-validation scores were consistent, with a maximum accuracy of 57.71%, confirming the model's limitations.</p>
                
                <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                    <img src="./Results/naive_bayes/tuned_model_cv_scores.png" alt="Tuned Model Cross-validation Scores" style="flex: 1; max-width: 45%;">
                    <img src="./Results/naive_bayes/tuned_model_roc_auc.png" alt="Tuned Model ROC-AUC" style="flex: 1; max-width: 45%;">
                </div>

                <h3>AUC-ROC Curve</h3>
                <p>The AUC-ROC curve gave us an area under the curve of 0.61. While the model offers fast computation and simplicity, it’s clear that more advanced methods are needed to achieve higher performance on this task.</p>
            </section>
        </div>
                
        <style>
            #conclusion-results {
                font-size: 1.2rem; /* Slightly smaller font size for general content */
                line-height: 1.6; /* Maintains readability with balanced line spacing */
                padding: 20px; /* Adds spacing around the content */
            }
            #conclusion-results h1 {
                font-size: 2rem; /* Adjusts font size for main headings */
                margin-bottom: 20px;
            }
            #conclusion-results h2 {
                font-size: 1.6rem; /* Adjusts font size for subheadings */
                margin-top: 20px;
            }
            #conclusion-results p {
                margin-bottom: 15px; /* Spacing below paragraphs */
            }
            #conclusion-results ul {
                margin: 15px 0;
                padding-left: 30px; /* Slightly reduces indentation for list items */
            }
            #conclusion-results ul li {
                font-size: 1.2rem; /* Ensures list items are proportionate */
                margin-bottom: 8px;
            }
        </style>
        
        <div id="conclusion-results" class="tab-content">
            <h1>Conclusion & Results</h1>
            <p>Our project, "<strong>Fire in Focus: An Analytical Approach to Analyzing Wildfires</strong>," explores the critical challenge of wildfires in Southern California. The findings from our analysis and predictive modeling offer valuable insights into wildfire patterns and their relationship with environmental factors.</p>
            <h2>Key Findings:</h2>
            <ul>
                <li>Wildfires are most frequent during the hottest months (June–September) and strongly correlate with high temperatures and low humidity.</li>
                <li>Southern California is a significant hotspot for wildfire activity, emphasizing the need for localized prevention strategies.</li>
                <li>The predictive models we developed can forecast wildfire occurrences with high accuracy, helping in early warning systems and resource optimization.</li>
            </ul>
            <h2>Significance of Findings:</h2>
            <ul>
                <li>These insights contribute to a better understanding of wildfires, enabling improved preparation and response strategies for communities and authorities.</li>
                <li>Our analysis talks about the role of meteorological factors, which can guide policymakers in implementing climate-resilient wildfire management plans.</li>
            </ul>
            <h2>Future Improvements:</h2>
            <ul>
                <li>Incorporating additional environmental data, such as vegetation density and soil moisture, could enhance the model's precision.</li>
                <li>Exploring real-time data integration and adaptive algorithms would make predictions more dynamic and actionable.</li>
                <li>Collaborative efforts with fire management agencies can lead to tailored solutions for high-risk regions.</li>
            </ul>
            <h2>Potential Use Cases:</h2>
            <ul>
                <li><strong>Emergency Preparedness:</strong> Our predictive tool can assist in deploying resources to control fires more effectively.</li>
                <li><strong>Urban Planning:</strong> Insights from the data can inform decisions about zoning and building codes in vulnerable areas.</li>
                <li><strong>Climate Research:</strong> The findings can support studies on the impact of climate change on wildfire patterns.</li>
            </ul>
        </div>
                
        <div id="team" class="tab-content">
            <h1>Meet Our Team</h1>
            <div class="team-member">
                <img src="images/olan.jpeg" alt="Team Member 1">
                <h2>Olan Pinto</h2>
                <a href="https://www.linkedin.com/in/olan-pinto/">LinkedIn</a>
            </div>
            <div class="team-member">
                <img src="images/abhiram.jpeg" alt="Team Member 2">
                <h2>Abhiram Venkatarangan</h2>
                <a href="https://www.linkedin.com/in/abhiram-m-v-4a0413182/">LinkedIn</a>
            </div>
            <div class="team-member">
                <img src="images/rissi.jpg" alt="Team Member 3">
                <h2>Rissi Kumar Prabhakaran</h2>
                <a href="https://www.linkedin.com/in/rissi-kumar-prabhakaran/">LinkedIn</a>
            </div>
        </div>
    </div>

    <script>
        function showTab(tabId) {
            const tabs = document.querySelectorAll('.tab-content');
            tabs.forEach(tab => tab.style.display = 'none'); // Hide all tabs
            document.getElementById(tabId).style.display = 'block'; // Show the selected tab
        }

        // Show the introduction tab by default
        showTab('introduction');
    </script>
</body>
</html>
